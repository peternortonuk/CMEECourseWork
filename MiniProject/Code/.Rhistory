if (distance > 0.1){
distance = 0.9*distance
fern(coords, distance = 0.38*distance1, direction = 3*pi/4 )
fern(coords, distance= 0.87*distance2, direction = (pi/2) )
}
}
plot(NA, xlim=c(0,2), ylim=c(0,5), xlab="X", ylab="Y")
graphics.off()
plot(NA, xlim=c(0,2), ylim=c(0,5), xlab="X", ylab="Y")
fern(c(1,0),1,1)
graphics.off()
plot(NA, xlim=c(0,2), ylim=c(0,10), xlab="X", ylab="Y")
fern(c(1,0),1,1)
graphics.off()
plot(NA, xlim=c(0,2), ylim=c(0,10), xlab="X", ylab="Y")
fern = function(start, distance, direction) {
coords = turtle(start, distance, direction)
distance1 = distance
distance2 = distance
#coords = turtle(start, distance, direction)
if (distance > 0.01){
distance = 0.9*distance
fern(coords, distance = 0.38*distance1, direction = 3*pi/4 )
fern(coords, distance= 0.87*distance2, direction = (pi/2) )
}
}
fern(c(1,0),1,1)
fern = function(start, distance, direction) {
coords = turtle(start, distance, direction)
distance1 = distance
distance2 = distance
#coords = turtle(start, distance, direction)
if (distance > 0.01){
distance = 0.9*distance
fern(coords, distance = 0.38*distance1, direction = 3*pi/4 )
fern(coords, distance= 0.75*distance2, direction = (pi/2) )
}
}
fern2 = function(start, distance, direction) {
coords = turtle(start, distance, direction)
distance1 = distance
distance2 = distance
#coords = turtle(start, distance, direction)
if (distance > 0.01){
distance = 0.9*distance
fern(coords, distance = 0.38*distance1, direction = 3*pi/4 )
fern(coords, distance= 0.75*distance2, direction = (pi/2) )
}
}
graphics.off()
plot(NA, xlim=c(0,2), ylim=c(0,10), xlab="X", ylab="Y")
fern2(c(1,0),1,1)
graphics.off()
plot(NA, xlim=c(0,2), ylim=c(0,10), xlab="X", ylab="Y")
fern2(c(1,0),0.7,1)
knitr::opts_chunk$set(echo = TRUE)
graphics.off()
plot(NA, xlim=c(0,2), ylim=c(0,10), xlab="X", ylab="Y")
fern = function(start, distance, direction) {
coords = turtle(start, distance, direction)
distance1 = distance
distance2 = distance
#coords = turtle(start, distance, direction)
if (distance > 0.01){
distance = 0.9*distance
fern(coords, distance = 0.38*distance1, direction = 3*pi/4 )
fern(coords, distance= 0.87*distance2, direction = (pi/2) )
}
}
fern(c(1,0),1,1)
load("/home/petra/Documents/CMEECourseWork/HPC/Results/Cluster_1207/pg5117/pg5117_cluster_1.rda")
installed.packages()
library(ggraph)
knitr::opts_chunk$set(echo = FALSE, comment=NA)
#clear the workspace
rm(list = ls())
cat("\014")
#setwd("~/Documents/CMEECourseWork/MiniProject/Code")
#Get the data , enter input CSV file name here, for data in data directory
inputfile = 'SorariaCompact1.csv'
Dataname = strsplit(inputfile, "\\.")[[1]][[1]]
fullfile = paste("../Data",inputfile,sep = '/')
Data = read.csv(fullfile)
setwd("~/Documents/CMEECourseWork/MiniProject/Code")
#Get the data , enter input CSV file name here, for data in data directory
inputfile = 'SorariaCompact1.csv'
Dataname = strsplit(inputfile, "\\.")[[1]][[1]]
fullfile = paste("../Data",inputfile,sep = '/')
Data = read.csv(fullfile)
speciesnames = as.character(unique(unlist(Data$Species))) # uselful for nameing things
numspecies = summary(Data$Species) # useful for comparisons
#Median imputation
median_replace1 = function(x){
ifelse(is.na(x), median(x,na.rm = TRUE), x)
}
median_replace2 = function(x){
apply(x,2,median_replace1)
}
Imputed_list = lapply(split.data.frame(Data[,2:12], Data$Species), FUN = median_replace2)
#The imputed dataframe is a list with species as the elements, the following sticks it back together with a different name so both optiona are available
temp = do.call(rbind, Imputed_list)
Imputed_df = cbind(Data[1], temp)
# Some algorthms are sensitive to the scale of the data, so here the entire dataframe is scaled
Scaled_df = scale(Imputed_df[-1])
Scaled_df = cbind(Data[1], Scaled_df)
# but this might reduce the dissimilarity to much, so this is a semi-scaled datafrane.
temp = Imputed_df[-c(1,6,7,8,12)]
temp = scale(temp)
Semi_Scaled_df = cbind(Imputed_df[c(1,6:8,12)], temp)
knitr::opts_chunk$set(echo = FALSE,message = FALSE,fig.pos = "H" ,comment=NA, fig.align ="centre")
#Disaply BSS/WSS ratio for the kmeans calculated in chunk above
SS_df = data.frame(nrow = 3)
SS_df = rbind(Imputed_kmeans[[1]],Semi_scaled_kmeans[[1]],Scaled_kmeans[[1]])
#clear the workspace
rm(list = ls())
cat("\014")
#setwd("~/Documents/CMEECourseWork/MiniProject/Code")
library(ggplot2)
library(reshape) # both required for the box plots, otherwise they cant all be presented
# on one page and therefore difficult to analyse
library(rpart)
library(rpart.plot)# both required for the decision tree
library(knitr)
#Get the data , enter input CSV file name here, for data in data directory
inputfile = 'SorariaCompact1.csv'
Dataname = strsplit(inputfile, "\\.")[[1]][[1]]
fullfile = paste("../Data",inputfile,sep = '/')
Data = read.csv(fullfile)
speciesnames = as.character(unique(unlist(Data$Species))) # uselful for nameing things
numspecies = summary(Data$Species) # useful for comparisons
#Median imputation
median_replace1 = function(x){
ifelse(is.na(x), median(x,na.rm = TRUE), x)
}
median_replace2 = function(x){
apply(x,2,median_replace1)
}
Imputed_list = lapply(split.data.frame(Data[,2:12], Data$Species), FUN = median_replace2)
#The imputed dataframe is a list with species as the elements, the following sticks it back together with a different name so both optiona are available
temp = do.call(rbind, Imputed_list)
Imputed_df = cbind(Data[1], temp)
# Some algorthms are sensitive to the scale of the data, so here the entire dataframe is scaled
Scaled_df = scale(Imputed_df[-1])
Scaled_df = cbind(Data[1], Scaled_df)
# but this might reduce the dissimilarity to much, so this is a semi-scaled datafrane.
temp = Imputed_df[-c(1,6,7,8,12)]
temp = scale(temp)
Semi_Scaled_df = cbind(Imputed_df[c(1,6:8,12)], temp)
# Model evaluation metrics
accuracy = function(atable){
a = round(sum(diag(atable)/sum(atable)), digits = 2)
return(a)
}
# precision = TP/( rest of that column in conf matrix = the other species id in same class)
precision = function(atable){
p = vector()
items = vector()
no_predictions = dim(atable)[2]
for (i in 1:no_predictions){
items[i] = paste("class",colnames(atable)[i], sep = "_")
p[i] = round(diag(atable)[i]/(sum((atable)[,i])), digits = 2)
}
precisions = cbind(items,p)
colnames(precisions) = c("Class", "Precision")
return(precisions)
}
#sensitivity = TP/ rest of that row = the other classes the algorithm has put species in
sensitivity = function(atable){
s = vector()
no_actuals = dim(atable)[1]
for (i in 1:no_actuals){
s[i] = round(diag(atable)[i]/(sum((atable)[i,])), digits = 2)
}
sensitivities = cbind(rownames(atable),s)
colnames(sensitivities) = c("Species", "Sensitivity")
return(sensitivities)
}
#Data sampling and test/train sets.
#This shuffles and splits the data
shuffle = function(dataset){
splits = list()
set.seed(42)
n = nrow(dataset)
shuffled = dataset[sample(n),]
train = shuffled[1:round(0.7*n),]
test = shuffled[(round(0.7*n)+1):n,]
splits[[1]] = train
splits[[2]] = test
return(splits)
}
#this subsets the data into species
create_train_test = function(dataset){
sets = as.character(unique(dataset[,1]))
train = data.frame()
test = data.frame()
split_data = list()
for (i in 1:length(sets)){
sub = subset(dataset, dataset[,1] == sets[i])
train_temp = shuffle(sub)[[1]]
test_temp = shuffle(sub)[[2]]
train = rbind(train, train_temp)
test = rbind(test, test_temp)
}
split_data[[1]] = train
split_data[[2]] = test
return(split_data)
}
#PS you can check the splits are correct with summary(train$species), summary(test$species)
#summary(maindata$species), this gives numbers in each species.
#to include a cross fold validation repeat above fold times
# performs the k means algorith over 10 repeats, returns BSS/Wss ratio, accuracy and
repeated_kmeans = function(dataset){
metrics_list = list()
accuracy_vector = vector()
ratio = vector()
species_no = data.frame(matrix(ncol = 7))
colnames(species_no) = speciesnames
for (i in 1:10){
kmeans_result = kmeans(dataset[-1], 7, 20, iter.max = 50, algorithm = "MacQueen")
ratio[i] = round(kmeans_result$tot.withinss/kmeans_result$totss, digits = 2)
kmeans_conf = table(Imputed_df$Species, kmeans_result$cluster)
accuracy_vector[i] = accuracy(kmeans_conf)
species = diag(kmeans_conf)
species_no = rbind(species_no, species)# just TP
}
metrics_list[[1]] = ratio # wss/bss
metrics_list[[2]] = accuracy_vector #sum TP/no things done
metrics_list[[3]] = species_no[-1,]
return(metrics_list)
}
#Getting the results for the kmeans
#Imputed df without scaling
Imputed_kmeans = repeated_kmeans(Imputed_df)
#Semi scaled data
Semi_scaled_kmeans = repeated_kmeans(Semi_Scaled_df)
# fully scaled data
Scaled_kmeans = repeated_kmeans(Scaled_df)
#Disaply BSS/WSS ratio for the kmeans calculated in chunk above
SS_df = data.frame(nrow = 3)
SS_df = rbind(Imputed_kmeans[[1]],Semi_scaled_kmeans[[1]],Scaled_kmeans[[1]])
rownames(SS_df) = c("unstandardized","semi-standardized","fully standardized")
colnames(SS_df) = c("Run 1","Run 2","Run 3","Run 4","Run 5","Run 6","Run 7", "Run 8","Run 9","Run 10")
kable(SS_df, format = "pandoc", caption = "Within cluster to between cluster ratio")
#Display accuaracy for kmeans calcualted above
prec_df = data.frame(nrow = 3)
prec_df = rbind(Imputed_kmeans[[2]],Semi_scaled_kmeans[[2]],Scaled_kmeans[[2]])
rownames(prec_df) = c("unstandardized","semi-standardized","fully standardized")
colnames(prec_df) = c("Run 1","Run 2","Run 3","Run 4","Run 5","Run 6","Run 7", "Run 8","Run 9","Run 10")
kable(prec_df, format = "pandoc", caption = "Accuracy")
#Display percentage of true positives from the confusion matrix calcualted in kmeans chunk above
m1 = Imputed_kmeans[[3]]
m2 = Semi_scaled_kmeans[[3]]
m3 = Scaled_kmeans[[3]]
m1
kmeans(Imputed_df[-1])
kmeans(Imputed_df[-1],7,20, iter.max = 50, algorithm = "MacQueen"
)
kmeans_test = kmeans(Imputed_df[-1],7,20, iter.max = 50, algorithm = "MacQueen"
)
test_conf =  table(Imputed_df$Species, kmeans_test$cluster)
test_conf
s = sensitivity(test_conf)
s
s[,2]
repeated_kmeans_test = function(dataset){
metrics_list = list()
accuracy_vector = vector()
ratio = vector()
species_no = data.frame(matrix(ncol = 7))
colnames(species_no) = speciesnames
s = data.frame(row.names = speciesnames,  nrow = 7, )
for (i in 1:10){
kmeans_result = kmeans(dataset[-1], 7, 20, iter.max = 50, algorithm = "MacQueen")
ratio[i] = round(kmeans_result$tot.withinss/kmeans_result$totss, digits = 2)
kmeans_conf = table(Imputed_df$Species, kmeans_result$cluster)
accuracy_vector[i] = accuracy(kmeans_conf)
species = diag(kmeans_conf)
species_no = rbind(species_no, species)# just TP
s = sensitivity(kmeans_conf)
sens = colbind(sens, s[ens][,2])
}
metrics_list[[1]] = ratio # wss/bss
metrics_list[[2]] = accuracy_vector #sum TP/no things done
metrics_list[[3]] = species_no[-1,]
metrics_list[[4]] = sens
return(metrics_list)
}
test_imputed = repeated_kmeans_test(Imputed_df)
s = data.frame(row.names = speciesnames,  nrow = 7 )
?data.frame
s = data.frame(row.names = speciesnames )
s
repeated_kmeans_test = function(dataset){
metrics_list = list()
accuracy_vector = vector()
ratio = vector()
species_no = data.frame(matrix(ncol = 7))
colnames(species_no) = speciesnames
s = data.frame(row.names = speciesnames )
for (i in 1:10){
kmeans_result = kmeans(dataset[-1], 7, 20, iter.max = 50, algorithm = "MacQueen")
ratio[i] = round(kmeans_result$tot.withinss/kmeans_result$totss, digits = 2)
kmeans_conf = table(Imputed_df$Species, kmeans_result$cluster)
accuracy_vector[i] = accuracy(kmeans_conf)
species = diag(kmeans_conf)
species_no = rbind(species_no, species)# just TP
s = sensitivity(kmeans_conf)
sens = colbind(sens, s[ens][,2])
}
metrics_list[[1]] = ratio # wss/bss
metrics_list[[2]] = accuracy_vector #sum TP/no things done
metrics_list[[3]] = species_no[-1,]
metrics_list[[4]] = sens
return(metrics_list)
}
test = repeated_kmeans_test(Imputed_df)
repeated_kmeans_test = function(dataset){
metrics_list = list()
accuracy_vector = vector()
ratio = vector()
species_no = data.frame(matrix(ncol = 7))
colnames(species_no) = speciesnames
s = data.frame(row.names = speciesnames )
for (i in 1:10){
kmeans_result = kmeans(dataset[-1], 7, 20, iter.max = 50, algorithm = "MacQueen")
ratio[i] = round(kmeans_result$tot.withinss/kmeans_result$totss, digits = 2)
kmeans_conf = table(Imputed_df$Species, kmeans_result$cluster)
accuracy_vector[i] = accuracy(kmeans_conf)
species = diag(kmeans_conf)
species_no = rbind(species_no, species)# just TP
s = sensitivity(kmeans_conf)
sens = cbind(sens, s[ens][,2])
}
metrics_list[[1]] = ratio # wss/bss
metrics_list[[2]] = accuracy_vector #sum TP/no things done
metrics_list[[3]] = species_no[-1,]
metrics_list[[4]] = sens
return(metrics_list)
}
test = repeated_kmeans_test(Imputed_df)
repeated_kmeans_test = function(dataset){
metrics_list = list()
accuracy_vector = vector()
ratio = vector()
species_no = data.frame(matrix(ncol = 7))
colnames(species_no) = speciesnames
s = data.frame(row.names = speciesnames )
for (i in 1:10){
kmeans_result = kmeans(dataset[-1], 7, 20, iter.max = 50, algorithm = "MacQueen")
ratio[i] = round(kmeans_result$tot.withinss/kmeans_result$totss, digits = 2)
kmeans_conf = table(Imputed_df$Species, kmeans_result$cluster)
accuracy_vector[i] = accuracy(kmeans_conf)
species = diag(kmeans_conf)
species_no = rbind(species_no, species)# just TP
s = sensitivity(kmeans_conf)
sens = cbind(sens, s[,2])
}
metrics_list[[1]] = ratio # wss/bss
metrics_list[[2]] = accuracy_vector #sum TP/no things done
metrics_list[[3]] = species_no[-1,]
metrics_list[[4]] = sens
return(metrics_list)
}
test = repeated_kmeans_test(Imputed_df)
repeated_kmeans_test = function(dataset){
metrics_list = list()
accuracy_vector = vector()
ratio = vector()
species_no = data.frame(matrix(ncol = 7))
colnames(species_no) = speciesnames
sens = data.frame(row.names = speciesnames )
for (i in 1:10){
kmeans_result = kmeans(dataset[-1], 7, 20, iter.max = 50, algorithm = "MacQueen")
ratio[i] = round(kmeans_result$tot.withinss/kmeans_result$totss, digits = 2)
kmeans_conf = table(Imputed_df$Species, kmeans_result$cluster)
accuracy_vector[i] = accuracy(kmeans_conf)
species = diag(kmeans_conf)
species_no = rbind(species_no, species)# just TP
s = sensitivity(kmeans_conf)
sens = cbind(sens, s[,2])
}
metrics_list[[1]] = ratio # wss/bss
metrics_list[[2]] = accuracy_vector #sum TP/no things done
metrics_list[[3]] = species_no[-1,]
metrics_list[[4]] = sens
return(metrics_list)
}
test = repeated_kmeans_test(Imputed_df)
test[[4]]
repeated_kmeans_test = function(dataset){
metrics_list = list()
accuracy_vector = vector()
ratio = vector()
species_no = data.frame(matrix(ncol = 7))
colnames(species_no) = speciesnames
sens = data.frame(row.names = speciesnames )
prec = data.frame(rownames = speciesnames)
for (i in 1:10){
kmeans_result = kmeans(dataset[-1], 7, 20, iter.max = 50, algorithm = "MacQueen")
ratio[i] = round(kmeans_result$tot.withinss/kmeans_result$totss, digits = 2)
kmeans_conf = table(Imputed_df$Species, kmeans_result$cluster)
accuracy_vector[i] = accuracy(kmeans_conf)
species = diag(kmeans_conf)
species_no = rbind(species_no, species)# just TP
s = sensitivity(kmeans_conf)
sens = cbind(sens, s[,2])
p = precision(kmeans_conf)
prec = cbind(prec,p[,2])
}
metrics_list[[1]] = ratio # wss/bss
metrics_list[[2]] = accuracy_vector #sum TP/no things done
metrics_list[[3]] = species_no[-1,]
metrics_list[[4]] = sens
metrics_list[[5]] = prec
return(metrics_list)
}
test = repeated_kmeans_test(Imputed_df)
test[[5]]
#Display accuaracy for kmeans calcualted above. this is accuarcy, not repcision
acc_df = data.frame(nrow = 3)
acc_df = rbind(Imputed_kmeans[[2]],Semi_scaled_kmeans[[2]],Scaled_kmeans[[2]])
rownames(acc_df) = c("unstandardized","semi-standardized","fully standardized")
colnames(acc_df) = c("Run 1","Run 2","Run 3","Run 4","Run 5","Run 6","Run 7", "Run 8","Run 9","Run 10")
kable(acc_df, format = "pandoc", caption = "Accuracy")
prec_df_Imputed = Imputed_kmeans[[4]]
#Getting the results for the kmeans
#Imputed df without scaling
Imputed_kmeans = repeated_kmeans(Imputed_df)
#Semi scaled data
Semi_scaled_kmeans = repeated_kmeans(Semi_Scaled_df)
# fully scaled data
Scaled_kmeans = repeated_kmeans(Scaled_df)
Imputed_kmeans = repeated_kmeans(Imputed_df)
prec_df_Imputed = Imputed_kmeans[[4]]
Imputed_kmeans[[4]]
# performs the k means algorith over 10 repeats, returns BSS/Wss ratio, accuracy and
repeated_kmeans = function(dataset){
metrics_list = list()
accuracy_vector = vector()
ratio = vector()
species_no = data.frame(matrix(ncol = 7))
colnames(species_no) = speciesnames
sens = data.frame(row.names = speciesnames )
prec = data.frame(rownames = speciesnames)
for (i in 1:10){
kmeans_result = kmeans(dataset[-1], 7, 20, iter.max = 50, algorithm = "MacQueen")
ratio[i] = round(kmeans_result$tot.withinss/kmeans_result$totss, digits = 2)
kmeans_conf = table(Imputed_df$Species, kmeans_result$cluster)
accuracy_vector[i] = accuracy(kmeans_conf)
species = diag(kmeans_conf)
species_no = rbind(species_no, species)# just TP
s = sensitivity(kmeans_conf)
sens = cbind(sens, s[,2])
p = precision(kmeans_conf)
prec = cbind(prec,p[,2])
}
metrics_list[[1]] = ratio # wss/bss
metrics_list[[2]] = accuracy_vector #sum TP/no things done
metrics_list[[3]] = species_no[-1,]
metrics_list[[4]] = sens
metrics_list[[5]] = prec
return(metrics_list)
}
#Getting the results for the kmeans
#Imputed df without scaling
Imputed_kmeans = repeated_kmeans(Imputed_df)
#Semi scaled data
Semi_scaled_kmeans = repeated_kmeans(Semi_Scaled_df)
# fully scaled data
Scaled_kmeans = repeated_kmeans(Scaled_df)
#Disaply BSS/WSS ratio for the kmeans calculated in chunk above
SS_df = data.frame(nrow = 3)
SS_df = rbind(Imputed_kmeans[[1]],Semi_scaled_kmeans[[1]],Scaled_kmeans[[1]])
rownames(SS_df) = c("unstandardized","semi-standardized","fully standardized")
colnames(SS_df) = c("Run 1","Run 2","Run 3","Run 4","Run 5","Run 6","Run 7", "Run 8","Run 9","Run 10")
kable(SS_df, format = "pandoc", caption = "Within cluster to between cluster ratio")
#Display accuaracy for kmeans calcualted above. this is accuarcy, not repcision
acc_df = data.frame(nrow = 3)
acc_df = rbind(Imputed_kmeans[[2]],Semi_scaled_kmeans[[2]],Scaled_kmeans[[2]])
rownames(acc_df) = c("unstandardized","semi-standardized","fully standardized")
colnames(acc_df) = c("Run 1","Run 2","Run 3","Run 4","Run 5","Run 6","Run 7", "Run 8","Run 9","Run 10")
kable(acc_df, format = "pandoc", caption = "Accuracy")
#Display percentage of true positives from the confusion matrix calcualted in kmeans chunk above
m1 = Imputed_kmeans[[3]]
m2 = Semi_scaled_kmeans[[3]]
m3 = Scaled_kmeans[[3]]
m1_percent = round(apply(m1, 1, function(x) (x/numspecies)*100), digits = 2)
colnames(m1_percent) = c(1:10)
kable(m1_percent, format = "pandoc", caption = "Percentage of true positives for non-standarized data")
m2_percent = round(apply(m2, 1, function(x) (x/numspecies)*100), digits = 2)
colnames(m2_percent) = c(1:10)
kable(m2_percent, format = "pandoc", caption = "Percentage of true positives for semi-standarized data" )
m3_percent = round(apply(m3, 1, function(x) (x/numspecies)*100), digits = 2)
colnames(m3_percent) = c(1:10)
kable(m3_percent, format = "pandoc", caption = "Percentage of true positives for fully standarized data")
prec_df_Imputed = Imputed_kmeans[[4]]
prec_df_Imputed
prec_df_Imputed = Imputed_kmeans[[4]]
colnames(prec_df_Imputed) = c(1:10)
prec_df_Imputed = Imputed_kmeans[[4]]
colnames(prec_df_Imputed) = c(1:10)
prec_df_Imputed
prec_df_Imputed = Imputed_kmeans[[4]]
colnames(prec_df_Imputed) = c(1:10)
kable(prec_df_Imputed, format = "pandoc", caption = "Precision of kmeans with non standardized data")
sens_df_Imputed = Imputed_kmeans[[4]]
colnames(sens_df_Imputed) = c(1:10)
kable(sens_df_Imputed, format = "pandoc", caption = "Sensitivity of kmeans with non standardized data")
prec_df_SS = Semi_Scaled_kmeans[[4]]
prec_df_SS = Semi_scaled_kmeans[[4]]
colnames(prec_df_SS) = c(1:10)
kable(prec_df_SS, format = "pandoc", caption = "Precision of kmeans with semi-standardized data")
